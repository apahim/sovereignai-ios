<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quickstart - SovereignAI</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            color: #1d1d1f;
            background: #fff;
            line-height: 1.7;
        }
        .container { max-width: 720px; margin: 0 auto; padding: 60px 24px; }
        h1 { font-size: 2em; font-weight: 700; margin-bottom: 4px; }
        .updated { color: #86868b; margin-bottom: 40px; font-size: 0.9em; }
        h2 { font-size: 1.15em; font-weight: 600; margin-top: 32px; margin-bottom: 8px; }
        h3 { font-size: 1em; font-weight: 600; margin-top: 16px; margin-bottom: 4px; }
        p { color: #424245; margin-bottom: 12px; }
        ul, ol { padding-left: 20px; margin-bottom: 12px; }
        li { color: #424245; margin-bottom: 4px; }
        code {
            font-family: "SF Mono", SFMono-Regular, Menlo, Consolas, monospace;
            font-size: 0.9em;
            background: #f5f5f7;
            padding: 2px 6px;
            border-radius: 4px;
        }
        pre {
            background: #f5f5f7;
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
            margin-bottom: 12px;
        }
        pre code { background: none; padding: 0; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .back { margin-top: 48px; padding-top: 24px; border-top: 1px solid #e5e5e5; }
        footer { margin-top: 48px; color: #86868b; font-size: 0.85em; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Quickstart</h1>
        <p class="updated">Get up and running with SovereignAI and Ollama</p>

        <p>This guide walks you through installing Ollama, downloading a model, and connecting SovereignAI to it. The whole process requires just a few commands.</p>

        <h2>1. Install Ollama</h2>

        <h3>macOS</h3>
        <p>Download Ollama from <a href="https://ollama.com/download">ollama.com/download</a> and drag it to your Applications folder. Alternatively, install with Homebrew:</p>
        <pre><code>brew install ollama</code></pre>

        <h3>Linux (Ubuntu / Debian)</h3>
        <pre><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre>

        <h3>Linux (Fedora)</h3>
        <pre><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre>

        <h3>Windows</h3>
        <p>Download the installer from <a href="https://ollama.com/download">ollama.com/download</a> and run it.</p>

        <h2>2. Pull the model and start the server</h2>

        <p>Open a terminal (or PowerShell on Windows) and download the Mistral Nemo 12B Instrict model:</p>
        <pre><code>ollama pull mistral-nemo:12b-instruct-2407-q4_K_M</code></pre>
        <p>This is roughly 7.5 GB and may take a while depending on your connection.</p>

        <p>Then start the server so it accepts connections from your phone:</p>
        <pre><code>OLLAMA_HOST=0.0.0.0 ollama serve</code></pre>
        <p>On Windows (PowerShell), set the variable first:</p>
        <pre><code>$env:OLLAMA_HOST="0.0.0.0"; ollama serve</code></pre>

        <h2>3. Find your server address</h2>
        <p>SovereignAI needs the local network IP of the machine running Ollama. Your iOS device and the machine must be on the same network.</p>
        <p>To find your IP address:</p>
        <ul>
            <li><strong>macOS</strong> &mdash; System Settings &gt; Wi-Fi &gt; Details, or run <code>ipconfig getifaddr en0</code></li>
            <li><strong>Linux</strong> &mdash; <code>hostname -I</code></li>
            <li><strong>Windows</strong> &mdash; <code>ipconfig</code> and look for the IPv4 address</li>
        </ul>
        <p>Your server address will be <code>http://&lt;your-ip&gt;:11434</code> (for example, <code>http://192.168.1.42:11434</code>).</p>

        <h2>4. Configure SovereignAI</h2>
        <p>Open SovereignAI on your iPhone or iPad. If this is your first launch, the onboarding wizard will guide you. Otherwise, go to Settings &gt; Server.</p>
        <ol>
            <li><strong>Server URL</strong> &mdash; Enter your Ollama address (e.g. <code>http://192.168.1.42:11434</code>).</li>
            <li><strong>Authentication</strong> &mdash; Select <strong>None</strong>. Ollama does not require authentication by default.</li>
            <li><strong>Test Connection</strong> &mdash; Tap the test button. You should see a success message and the list of available models.</li>
            <li><strong>Select Model</strong> &mdash; Choose <strong>mistral-nemo:12b-instruct-2407-q4_K_M</strong> from the list.</li>
        </ol>

        <p>That's it. Start a new chat and send a message.</p>

        <h2>Troubleshooting</h2>
        <ul>
            <li><strong>Connection refused</strong> &mdash; Make sure <code>ollama serve</code> is running with <code>OLLAMA_HOST=0.0.0.0</code> and that you are using the correct IP address and port.</li>
            <li><strong>Model not listed</strong> &mdash; Run <code>ollama list</code> to verify the model was downloaded. If not, run <code>ollama pull mistral-nemo:12b</code> again.</li>
            <li><strong>Slow responses</strong> &mdash; Mistral Nemo 12B Instruct works best with a dedicated GPU. On CPU-only machines, responses will be slower.</li>
            <li><strong>Firewall issues</strong> &mdash; Ensure port <code>11434</code> is not blocked by your firewall. On Fedora, you can open it with <code>sudo firewall-cmd --add-port=11434/tcp</code>.</li>
        </ul>

        <div class="back">
            <a href="index.html">&larr; Back to SovereignAI</a>
        </div>

        <footer>
            <p>&copy; 2026 Amador Pahim Segundo. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>
